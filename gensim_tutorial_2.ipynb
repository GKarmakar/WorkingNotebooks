{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NullHandler', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', '__version__', 'corpora', 'interfaces', 'logger', 'logging', 'matutils', 'models', 'parsing', 'scripts', 'similarities', 'summarization', 'topic_coherence', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "print(dir(gensim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of docs', 4)\n"
     ]
    }
   ],
   "source": [
    "raw_docs = [\"I am testing nlp using gensim\",\n",
    "            \"This will be helpful tutotial\",\n",
    "            \"I can use this for better use\",\n",
    "            \"People are waiting for me to teach them\"]\n",
    "print(\"Number of docs\", len(raw_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'am', 'testing', 'nlp', 'using', 'gensim'], ['this', 'will', 'be', 'helpful', 'tutotial'], ['i', 'can', 'use', 'this', 'for', 'better', 'use'], ['people', 'are', 'waiting', 'for', 'me', 'to', 'teach', 'them']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "gen_docs = [[word.lower() for word in word_tokenize(text)] for text in raw_docs]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim\n",
      "2\n",
      "(0, u'nlp')\n",
      "(1, u'i')\n",
      "(2, u'testing')\n",
      "(3, u'am')\n",
      "(4, u'using')\n",
      "(5, u'gensim')\n",
      "(6, u'this')\n",
      "(7, u'will')\n",
      "(8, u'tutotial')\n",
      "(9, u'helpful')\n",
      "(10, u'be')\n",
      "(11, u'better')\n",
      "(12, u'use')\n",
      "(13, u'can')\n",
      "(14, u'for')\n",
      "(15, u'me')\n",
      "(16, u'them')\n",
      "(17, u'people')\n",
      "(18, u'to')\n",
      "(19, u'waiting')\n",
      "(20, u'are')\n",
      "(21, u'teach')\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(gen_docs)\n",
    "print(dictionary[5])\n",
    "print(dictionary.token2id['testing'])\n",
    "for i in range(len(dictionary)):\n",
    "    print(i, dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(6, 1), (7, 1), (8, 1), (9, 1), (10, 1)], [(1, 1), (6, 1), (11, 1), (12, 2), (13, 1), (14, 1)], [(14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=4, num_nnz=25)\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)\n",
    "s = 0\n",
    "for i in corpus:\n",
    "    s += len(i)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 4 documents in 0 shards (stored under /Users/trinakarmakar/anaconda2/data/)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "sims = gensim.similarities.Similarity('/Users/trinakarmakar/anaconda2/data/', \n",
    "                                      tf_idf[corpus], num_features = len(dictionary))\n",
    "print(sims)\n",
    "print(len(sims))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'testing', 'for', 'this', 'gensim', 'tutorial', 'is', 'going', 'well']\n",
      "[(2, 1), (5, 1), (6, 1), (14, 1)]\n",
      "[(2, 0.6324555320336759), (5, 0.6324555320336759), (6, 0.31622776601683794), (14, 0.31622776601683794)]\n"
     ]
    }
   ],
   "source": [
    "query_doc = [w.lower() for w in word_tokenize(\"My testing for this gensim tutorial is going well\")]\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55205244,  0.0766965 ,  0.12171613,  0.05872202], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
