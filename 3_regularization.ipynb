{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "#train_subset = 10000\n",
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random values following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + beta_regul*tf.nn.l2_loss(weights)\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 20.380402\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 16.1%\n",
      "Minibatch loss at step 100: 5.466839\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 70.4%\n",
      "Minibatch loss at step 200: 4.761787\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 300: 3.333981\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 400: 3.824338\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 500: 2.575907\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 600: 2.326572\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 700: 2.159472\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 800: 1.950850\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 900: 2.214430\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 2.080764\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 1100: 1.560171\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1200: 1.471901\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1300: 1.377394\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1400: 1.224890\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1500: 1.030902\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1600: 1.280051\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1700: 1.151645\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1800: 1.032647\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1900: 1.027237\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 0.959337\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2100: 0.879111\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2200: 1.011892\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2300: 0.939516\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2400: 0.745485\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 0.706513\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2600: 0.813565\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2700: 0.870937\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2800: 0.851479\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2900: 0.725110\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 3000: 0.975070\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 87.7%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this comutation and iterate\n",
    "num_steps = 3001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  #tf.global_variables_initializer().run()\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul: 1e-3}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 100 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 parameter introduced a meta parameter and since I don't have any idea what would be right value of this parameter I would plot an accuracy \n",
    "by the meta parameter value (in log scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for regul in regul_val:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for step in range(num_steps):\n",
    "        # Pick on offset within the training data, which has been randomized\n",
    "        # Note: we could use better randomization across graph\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        #Generate a minibatch\n",
    "            batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset+batch_size),:]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed\n",
    "        # and the value is the numpy array to feed to it\n",
    "            feed_dict = {tf_train_dataset: batch_data, tf_train_labels : batch_labels, beta_regul : regul}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGNCAYAAADdHUEBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XecFPX9x/HXB/WnYI+JYsOuoFH0UAxq7JWYVbEgWEGN\nBVAxgqIYMJYIiqhAsIBiy4EVO0f0VCSgUc4W4ewCYiynIJFDFPj8/vjOyd7eXt+92b17Px+PfcDN\nznznM7uzs5/9tjF3R0RERCTXtYo7ABEREZG6UNIiIiIieUFJi4iIiOQFJS0iIiKSF5S0iIiISF5Q\n0iIiIiJ5QUmLiIiI5AUlLSIiIpIXlLSIiIhIXlDSItJIZnaema00s53jjiUOZnaDmS3NQrlfmtnf\nM11uru5XmoaZFZvZrUl/HxF9fjtncZ9rRvsYmKHydorKO6me211kZh+aWd5+9+dt4PkgOqlqe6ww\ns/0zvN8tzWxIS/0SjYFHj5YqW8e/MkvlYma/jz4jbZpyv1I9M9s1ek82y+I+DgH2AYanPNUU73e9\nPydmdpqZ9amhvPq6C9gQ6N2AbXPC6nEH0MydmvL3GcCh0XJLWj4nw/ttBwyJyp2d4bJFmspWwIos\nlb0/8BdgLFDehPuV6u1GuG49B3yRpX1cCjzn7guyVH5a7r7MzFoDP9dz09OBzYExKeW9b2at3f2n\nesZRbmYPAH8GxtUzlpygpCWL3P0fyX+bWRfgUHcvzPKurfZV8lf0Yc14c0Q+ao6vhZmt5e4/unt9\nL/D12k11T2R5v7GreH3jjiMNIws1HhWfETPbHDiMqj8mm0R9E4wslvcQcKGZ/c7dX81kTE1BzUM5\nxMzWMrPrzOxjM/vRzD4zs2vNbI2U9bqa2b/MbJGZ/c/M5pjZkOi5I4BphA//xKQmqGrbPs1sWzO7\nw8w+MLNyM/vGzArNbIs06/7KzG4zs7lRjHPN7G4zWy9pndZR3B9E6ywws4fMbMuKGNO1IadrpzWz\niVE8O5pZkZn9DxgfPXeQmT1iZvOSXq9hZvZ/aeLexcwejcoqN7PZSa/ZkdF+j0izXe/ouY7VvX5J\n1jWz8Wb2XfTejDezdVOOJe0vPDObZmZv1lS4mb1qZv82s73NbLqZlQNXJT3/x+i8+CHa/2Qz2zFN\nOT2jc2apmb1lZn+IYpuTtE6d36NqYj3HQt+Br6L9vGtmVaqkLfQfeSiKYZaZ/Uj4dVmpb4mt6hNQ\n3WPjaL09zOw+M/sk2u8X0bm9ftI+/wb8Nfrzy6TPyMap+03aZnsze8zMFprZkuh1PixlnYrXLGFm\nQ6Pzvjw6b7eq6fWKtr8h2n67aF+LzexrM7vRql4DMvH61reMQ6Myys3sTTPbJ3q+u5m9F5Xxmpnt\nkqaM35rZ42b2bbT9a2Z2ZNLz5wL3RX++mvSedE5ap9bz22q4XgAJQmL0Qm3vRVRWz+g4l0bvwz1m\ntkk169X2earSp8XM1jez0RauWz9G78OUitfPzGYChwDtk87z2dFzaT+HVsN1LslMYAlwTF1eh1yj\nmpYcYaFj1HNAAXA78CGwB3AZsC3QM1pvd2Ay8DpwJfATsCOhnRbgbeAawpfZaKAik55Zw+67RPt6\nAFgAbAdcABSY2W8rfnlaSExmAFsTqhbfBjYGjgXaAovNbHWgKIrnQeBmYH3gCKA9MD/aZ11/UTmw\nJjA1ejwM/C96rjvhHB4NLAR+R6j2bEtoiiOKuxPwEuGD+vcohh2APwBXR+V+BZwSxZ6sJ/Ceu79d\nS5wG3Al8AwwGdgHOI1TtVlyc7wdONLOD3b04Kb4tgX2BAXV4LdoCT0VlTSC8X5jZ2dH+nwQGAusA\nfYDpZtbR3f8brdeN8D6/QTi3fh2V9QVV35PG/Oq9gHCOPk7oI3IsMM7M3N3vSdnHbsC9hPfmduC9\nNPv/iaq/kA24AViPVU08RwGbEc7Pr4BdgXOBnYADo3UKCef48VGci6Pli9LsFwu/0GcSfuTdAnxP\n6BPwrJn90d2npMQ1BFgWxbYR4f2YABxEzSr6PDxG+PxfBuxHOKfXJZxPFTLx+tanjF2iYxgL/BDF\n9pSZXRwd71jCZ/FKwuu7W8XG0TVrGvAJcD2wFOgBPG1mR0ev3wtRGecRmu0+iTb/KCqjTuc3NV8v\nugBfuPs3qS98KjM7L3q9ZhA+l1sAFwFdzKzA3cuj9erzeUp1N+HacBvwQbTt/oRz9b3odbiZ0Adl\nAOF8/76GmGu7zgHg7m7hB9K+tb0OOcnd9WiiBzAKWFHNc2cTLsydUpZfSGhf3z36+zJgOdCmhv3s\nS7gInVTHuNZMs2z/qIzjk5YNi2I5vIayzo+2+1MN6xwRldM5ZflOqXETLoArgMF1jHsIod34N0nL\nXgPKgE1qiGkE4curddKyzaLXekAtr9+5UdyvAK2Slg+OYj80+ns14Evg7pTtB0Uxb1rLfmZG5Z2a\nsnz9KPaRKcs3i5bfkrTsfcIX4ppJyw6L4p/dwPfob0B5Hd6bYuDdlGX/jfazX5r1/wv8vYbX46po\n2+Nr2e8Z0XqdkpZdGS3buLb9Er5MlwMFScvWI3wppL5mK4ESYLWk5QOifW1by/v7t2j7f6QsHxft\nf4cMv771KWM50DFp2R+jWL9Pfg2BfqnnDTCd8BlM/mwYIWF6K2nZKdWcc/U5v2u6XvwbmJZmeaVz\nnZD0fButv3rSet2iY76sAZ+nNaNlA5OWLQGG13JO/DO5nFo+h7Ve55LWnQCU1bZeLj7UPJQ7TiDU\nXHxmZhtVPAgXEWPVr7RF0d/HZWrH7r6s4v9mtoaZ/YrQgbecUPNToRvwmrtPraG4boRf/3dlKr7I\n7akLUuJuE71eMwi/iHePlm8O7AXc4e5f1VD+fYRfb8cmLesZ/fuPqqtX4cDt7r4yadlownvVNYp3\nBeGi2s3M1kzZz4u+6tdiTf5HqMFK1hVYm9AcmHzu/ATMIjp3zGwbwi+ve5JfO3f/J+HCmzEp7836\nZvZrwq/tDla1+W6Ou0+vT/lR08IQwkX/0Wr2u1b0OrxGeB8KqhRUN0cBr7h7SdJ+FhOSiZ3MbNuU\n9cdF73WFV6J/U9dLxwm/kpONIpzTRyXtv9Gvbz3LeNMr1za+Fv07xd2/TlluRMdqZm0Jta6TgA2T\nzs2NCDUhu5rZhmleh2R1Or9TVLleRPtcWMu+INTIbAiMdvflFQvd/THgU0LNRSY+T4sJNTdVmpzq\nqx7XuQoLgQ3MLO/6PyppyR07EC6q36Q83iFcyDaO1ruf8AvgPgttzQ+YWaMSmOgL/zoz+xz4kZCt\nfw20JvzKqbAN8J9aituOcJHMZIe6cncvS11oZltHx/8docr6G1Y171TEvV3073up2yeLLsjvEn7t\nVegJvOx1H2nwUUqZi6KYtk5afB/hV/ofo2PoSKh6v4+6mZ/mtd2e8EUxk8rnzteEGrPfROtV9Kv4\nuLbYG8vMDjCzF81sCeEC+TWhutsIx5/s03qWvQ2hSv554IqU535tZmPM7CtC0v0NIQF3Kp/Ldd2X\nAVsSflGnquizkNpfZX7K3wsJx13bl3OF1C+8D6J/t06Kq9Gvbz3LmJfyd0UzxefVLK841h2if2+k\n6rk5KHpuY2pW2/mdun3a60WkLl/SWxHOlw/SPPc+q97vxn6eLgX2BD43s5lmdpXVoe9TNep0nUuS\nlU7PTUF9WnJHK8KvhstI/8GaC78MWduH0EGrK6FNtKeZPevuRzdw33cCJxLaT/9N+AVQ0baejcS2\nug/LatUsrzI6Juo7UwysBVxLuMCUs6q/TUPivg+4PvrFuTGhtiaj8xm4+5tm9h6hf8Yj0b/lhH4F\ndZFupFArwmt6Eul/STZklEF936NfmFl7wq/otwn9AD6PYjiW0A8h9b2p8+inqIbqUUKNY480Cdxk\nQj+W4YQkdAnhHHkqzX6zpbrh0hn5VZuJ17cBZVR3TLUda0U51wMvVrNuakKUqr7nd3Xn07fUPXHM\nOnd/0MxeJNSaH0a49l8W9ZOq7rXKlA2BRRn+cdkklLTkjo+BrepyskYn2vPR4xIzuxoYbGb7uPsM\n6p9BdwPudPeKXz6Y2Tqk/8X221rK+phQvWw1fCAqfnlukLJ86zpHDJ2i9U9Mbh4ws9TEreJXUG1x\nQ2h2uYHQwXczwsXv0Rq3qGwHVlWbY2YbEGo5PktZ7z7gmig5Ohl43N2X1GM/qSqO8atamlnmRv9u\nn+a57an8BdSY9+gYwrWla/IvXjP7Qx22rc0dhI7nXdy90hdYVM2+D6EP0oik5ene+zp9RtzdzWw+\noQ9Bqg7Rv3PTPNcYOxA6EVeoGCFTUWNyLI1/fbP5HiWrODeXeVLn82pU957U9fyuTSlwcB3Wm0s4\n93di1UCGCjux6v2uz+cpLXf/gjAHy5jo/H2bUANV8T1Q12t5fa5zEGrNMz0/WJNQ81DueAjY1sxO\nS30iar5pHf3/V2m2rWhrrugnUfEFmPqFU50VVD0X+qdZ71Fgb0szNDhlnc2BP9WwzqeED2PqTMDn\nU/cPacUF4Ze4o6r8i5LLiJp2/g38ycw2ralAd/+SMIrhdELT0FPu/r+atkliwHlWeXrsflEsz6as\n+yDhC2MMITl6oI77qM6zhNqawWZWpSYkav/H3T8lND2caWZrJT1/BKuq8Ss05j1K995sRCPnxzCz\n84HTgLPd/d267DfSn6ox1+cz8izw+2gUTEUs6xE6z5e6+ydJ6zb2l6sRajqSXRiVW9H0WdHPojGv\nb1beo1Tu/jnhi79PlKRXkrJsCekT5Tqd33UwE9g06mdT23oLgQuiGt2K/RxH+LJ/Gur9eUqNefXo\nh+Evor4oX7HqOg7hNan1HK3PdS66Tu5O6P+Xd1TTkjvGE5po7jGzwwkfnDWAnaPl+xHa5q8zswJg\nCqFadVPC0MVPWPUr/33Cyd7XzH4mfOBnuHtqW3uFZ4CzLdw/5oNoX/uyaghohesJVZlPmtl44C3C\nML1jCSNaPiA0zZxK+OWwL+GDsR5wODDM3f/p7mVm9gQwILoozCP88qtP1e270Xajoo6QSwjVx+uk\nWbcv4ZfLm2Z2F+EX0nbAwe6+d8q69xGSCCckHfWxDvBPM3uM8IvnT8Dz7v588kru/oWZFRPe168I\nIwQazN2/M7MLCZ2f3zCzSYSq8K2BowlfdhXzQ1xJ6BQ53czuIzSDnU9oC2+VVGZj3qMphHPlOTMb\nR7jo/onQQbvKF1ddRF80Iwnn3GpmdkrKKg9HMf+b8OW2NuG1PYowXDW1aWZWtGyYmT1KGL31uKef\nsOs6Qkf5F8zsNkLzaW/C8POzU0NtyPGl6BDF9DwhaexO6Nxb0cciE69vxt+jGpwHvAz8J9rXp4Tr\n1r6E8+l30XpvEj53g6P3exkwtZ7nd02eInRqPpSqPxR+ed88zF57BaFD9EtmNpHQr6kf4fo4Omm7\nOn2e0tgI+MDMHiZcy8oJTf2/JVzPK8wCEmZ2A+Hc/97dn6umzLpe5/YhdGyeXEN8uSvu4Ust6UH4\nwCyv4fnVgcsJnV2XEjqbvRotaxOtcyjhZPs8WmceYfjaVillHUf44Cwj/Kqqdvgz4YI1gdCxbRFh\nLoRtCHMNjElZdyNCDUHF/j8l9IlZL2md1oQL4seEjr3zCSNwtkhaZ2NCn5mKDrS3AB1TYyWMtvmq\nmrh3IVzYFxOGEo8idGaucryEfg6PEy52P0Sv8RVpymxN6Ez4NUnDVmt5X8+N9rk3IWn7NnodxwPr\nVrPNqYQhizfX4/yZSRi9Vd3zBxMu4AujY3w/em92S1mvJ6FqeCnhQngU4YI+K2W9ur5HfwOWpGx7\nDKETeTnh1+iFSa9T8hDZL4BJ1RzPL+cfoVp+RQ2PjaP1toje5++i9+H+aNkKUoauA0Oj83h5Shnp\nzvvtCbWICwkJ8nSioexJ61QMne2asrwi9hqnIIhexxWEkTePJp2HN5E09DaDr2+DyyDUBqwg/BBJ\nd6wXpCzfjvCD4L+Ea8Lc6H06OmW98wjXjZ+oOnS61vObGq4X0fNTgCered9Sh1r3IAxfXxq9D3eT\nfoh8rZ+npNdrQPT3WoTOyW8RrhXfE+Z66ZVS9rrRMX0XbT+7pnOKOlznCJ/j0rped3LtYdFBiAhg\nYajnl8AD7n5hFvdzEuFitJcnDaWNi4XZOz9w97ycJbM5sDBT70BCopt6PyTJADM7lFCzvL1XX/Oc\nif3k5OcpqoH8DBjk7nl576HY+7SYWSszu8bCtNvlZvaRmQ1OWWdtC9Mdz4/Wec/CtM+1lX2irZpe\n+W0zO6q2baTFO4kwNLauQ5Ab6k+EoeFNmrBEbemtUpYdSfjllu0RCyKx8tBUO50w3LjR8vDzdDah\nZueeuANpqFzo03I5oUrydEKfjT2BCWa2yN0r2g5HEqbg7kmoVjwcGGtmC9z96XSFRsOC/0EYRvYM\nYf6NyWa2h7vrzsdSiZn9jlV3mZ3h7m9kYR9G6J/QiTAhVk2dlbNlO8LnoJBQVb8L4fM3l1X3aBFp\nttz9kAwWl1efJ3e/Fbg17jgaI/bmITN7CvjS3c9JWvYIYYKgiht7vQtMdPfrktZ5A3jW3f9STbkT\nCf1AEknLZhJmdrwg3TbSckUXnW6Ejm9nuHtGZ4iN9rEmod17MaEjYD9v4g9gNPpsLKET5K+jWP5J\nqC6ubb4MyaKoeWgAoX+YmofygD5PTS8XkpZBwDnAEe7+oYUZQqcA/d19YrTOHYQhWsd5GHlxEKEz\nald3/1c15c4FRrj7bUnLhgLHuPseWT0oERERybhcaB6quEtrqZlVzBdyZUXCEulH6CX+uZlV9PQ/\np7qEJdKWyhM0Ef1d2xh9ERERyUG5kLR0J/RVOZnQp2V34FYz+8Ld74/WuZAwnPRowhDf/YG/R+vU\nNstinUWTFB1B6F39Y6bKFRERaQHWIsyfU+Tu32ZjB7mQtAwH/ubuD0d/v2dmWxOmMr4/mmnwOuBY\nXzWpzn/MbA9CD/DqkpYvgdS7Z24SLa/OEVS9g66IiIjU3SmEgTAZlwtJSxuq3qNhJauGY68RPVLX\nSTf1fLKZhJsK3pa07LBoeXU+A3jggQfo0KFDDau1LP3792fkyJFxh1GjOGLM5j4zVXZjy2nI9vXd\npj7r58O5GId8eF30Gc18OQ3dNluf0Tlz5nDqqadC1futZUwuJC1PEaZt/pwwg2sB4V4h4wDc/X9m\n9jJwk5n1IwwlO5AwRPriikLM7F5ggbtX3Kr+VsIUzJcQhjz3IAw1/WWUUho/AnTo0IGCgoKMHWC+\nW3/99XP+9YgjxmzuM1NlN7achmxf323qs34+nItxyIfXRZ/RzJfT0G2z+RmNZK17RS4kLX2BawhT\nw29MmDJ6bLSsQnfCFNcPAL8iJC6D3P3OpHW2JKk2xt1nmllPQtPSdYRpqo/RHC3116NHj7hDqFUc\nMWZzn5kqu7HlNGT7+m5Tn/W//LKm1t2WS5/Rpt9nLnxGG7ptNj+j2Rb7kOdcEt2IcNasWbNy/leL\nSEu0+eabs2DBgrjDEJE0SkpK6NSpE0CnbM32Hfs0/iIidRVdEEWkhVLSIiJ5I5eqqUWk6SlpEZG8\noaRFpGVT0iIiIiJ5QUmLiOSNXr16xR2CiMRISYuI5I3DDz887hBEJEZKWkQkb6hPi0jLpqRFRERE\n8oKSFhEREckLSlpEJG9Mnz497hBEJEZKWkQkbwwfPjzuEEQkRkpaRCRvTJw4Me4QRCRGuXCXZxGR\nOmnTpk3cIeScr7+G777LXvlbbAHrrJO98kXqQ0mLiEiecYeZM+Hmm+Hxx2Hlyuzta9114ayz4MIL\nYZttsrcfkbpQ0iIikieWL4fHHgvJymuvwY47wujRsNtu2dnfypVQVARjx8Jtt0G3bnDJJdClS3b2\nJ1IbJS0ikjcGDBjAjTfeGHcYTe7772HcuJA4zJsHBx8MTz8NRx0FrbLcM/H3v4crroD77oORI2Gf\nfWDvvUPy0q0brK5vEWlC6ogrInmjXbt2cYfQpD79FPr3D/1KBg2CAw+EN9+EF16AP/wh+wlLhTZt\n4LzzYM4ceOopWHtt6N4dttsu1Pp8/33TxCGipEVE8ka/fv3iDiHr3GHGDDjhBNh++1DDcdFFMHcu\n3Hsv7L57fLG1agVHHx2SpjffDEnU5ZfDlluG5OrTT+OLTVoGJS0iIjlg+XJ46KHQX2TffeE//4Ex\nY2D+fLj2Wth007gjrGz33UMS9dln0K9fSK623x5OPDF0EhbJBiUtIiIx+v57GDEiNLV07x6aXp5+\nGmbPDk0yuT7Ke7PN4LrrQnI1Zgy8807o9/K734UkbPnyuCOU5kRdqEQkL/TvDxMmlLLaau2zUv6a\na4Yhvdtuu+qx3Xbh37ZtwSyz+/v009Cxdtw4WLYMevQIxxhn809jVPR7+dOf4NlnQ6fd7t2hXbvQ\nvHXWWbD++nFHKfnO3D3uGHKGmRUAs2bNmkVBQUHc4YhIZP78kFC0bZugX78ns7KPJUtCIvHJJ+Hx\n5ZernmvduvqEZuut614bkjq/ygYbwPnnQ58+udf8kwlvvRWSl8JCWGstzffS3JWUlNCpUyeATu5e\nko19qKZFRHLebbeFWVmnTh3Nzjs3zT6XLAn9NT7+eFUi88kn8M9/hn+XLVu17qabpk9oKmppVqyo\nPL/KTjuFppTTT8/95p/GqOj38re/heO9/XbN9yKNo6RFRHLa4sVw552hRmLnnZtuyPPaa8Muu4RH\nqpUrQ03MJ59UTmo+/jgkNam1NG3awLffNu38Krmkot/LlVdWnu9l333D5Hj52iQmTU9Ji4jktHHj\noLw8jFDJFa1ahS/izTaD/far+nxFLU1FIlNWFoYwt/Qv59R+L4MGwZ57hj4vV1+texxJ7ZS0iEjO\nWr4cbr01dFLdfPO4o6m7mmppZNV8L0ccEZrMrr4aHn441LokEnFHJ7msBVVQiki+eeSRMG39n/8c\n/h42bFi8AUlGrbEGXHYZvPce/Pa3cMwxcNxxoeO1SDpKWkQkJ7mH+UsOOQQ6dgzLysvL4w1KsmKb\nbeCZZ8K8Lq+9BjvvDLfcojlepColLSKSk155Bd54Ay69dNWyq6++Or6AJKvMwmy6c+bAmWeG0UWd\nO4dzQKSCkhYRyUk33RT6hBxxRNyRSFNaf30YNQpefTXUtu29d5jbZfHiuCOTXKCkRURyzvvvh7sJ\nX3JJ5meilfzQuTO8/npIXu++Gzp0CH2cNB9qy6akRURyzsiRsMkmcMoplZeXlZXFE5DEYvXVw60N\nZs+GvfYKzUd//GMYTi4tk5IWEckp33wTZlHt2zfcDyhZ79694wlKYtWuHUyeHG598Pbbodlw+HD4\n+ee4I5OmpqRFRHLK2LGhSej886s+N3To0CaPR3LHsceGWpdzzw0T03XqFO7lJC2HkhYRyRlLl4YJ\nxnr1go02qvq8bmQq664bJqR7/fVQE7fvvmGW3YUL445MmoKSFhHJGQ88EKa8798/7kgk1xUUhBFG\nt90G//hH6KhbWKiOus2dkhYRyQkrV4Zf0MccA9tvH3c0kg9WWy30fSothf33h549wxD5jz+OOzLJ\nFiUtIpITnnsufPlUTNmfzvjx45suIMkbm20WZtN95hn48MNwS4Drrgs32pTmRUmLiOSEESPCRGL7\n7lv9OiUlJU0XkOSdrl3DfYwuugiGDg23B7jxRvjhh7gjk0xR0iIisSspgRdfDLUsNU0mN2bMmKYL\nSvJSmzZwww3wwQdhtNGVV8LWW4eal++/jzs6aSwlLSISuxEjwhfLccfFHYk0F9tsA3fcEfq3nHwy\nXHNNOMeGDIHvvos7Ommo2JMWM2tlZteY2SdmVm5mH5nZ4JR1VprZiujf5Ee1rd9mdkaa7dTCKZJj\n5s+HSZPg4ovDDKgimbTllmEY/SefhKH0N94YkpcrrggTGUp+iT1pAS4HzgUuANoDA4GBZtY3aZ22\nwKbRv22B3sBK4JFayv4+aZu2wFYZjVxEGu2222CddUCT3Uo2bbZZGJ322WdwwQXhvNt663AX8S+/\njDs6qatcSFq6AE+4+xR3n+fujwFTgc4VK7j718kP4FjgRXefW0vZ7u7fJG2rvFokhyxeDHfeGSYH\nW3fd2tdPJBLZD0qatY03Dn1e5s4NN+S8667QlHThhfD553FHJ7XJhaRlBnCIme0AYGYdgX2BZ9Ot\nbGYbA12BcXUoex0z+8zM5pnZZDPbOVNBi0jjjRsXhqX261e39fv27Vv7SiJ1sNFGoZ/L3LmhqeiB\nB2C77cLtI+bW9nNYYpMLScsNwCSg1Mx+AmYBt7j7xGrWPxNYDDxeS7nvE5qREsAphGOdYWabZSJo\nEWmc5cvh1luhRw/YfPO6bXP44YdnNyhpcTbYAK66KiQqf/0rPPJImNzwrLPgo4/ijk5S5ULS0h3o\nCZwM7AGcAQwws9OqWb8X8IC7/1RToe7+qrs/4O7vuPsrQDfgG0L/GRGJ2SOPwLx5NU8mJ9JU1l0X\nLrss9HkZNgyefRZ22glOOy1Meii5IReSluHADe7+sLu/5+4PAiOBQakrmtnvgR2pW9NQJe6+HHgT\nqHWC8K5du5JIJCo9unTpwuTJkyutN3Xq1LRt7H369Kkyc2dJSQmJRIKysrJKy4cMGcKwYcMqLZs3\nbx6JRILSlE/KqFGjGDBgQKVl5eXlJBIJpk+fXml5YWEhvXr1qhJb9+7ddRw6jtiPY9y48YwYAYcc\nAh075u9xNJf3Q8ex6jjmzy/lkkvCaKNbb4Wnnx5Fhw4D6N4d3n03f44j2+9HYWHhL9+Nbdu2JZFI\n0L8JbhpmHvPdpcysDLjC3e9MWjYIOMPd26esOwHY2d07U09m1gp4D3jG3S+tZp0CYNasWbN0N1mR\nLJo2DQ44IEzdf+SRdd9u8uTJHHvssdkLTCTFsmUwYULovPvZZ2EuocGDww0bpbKSkhI6deoE0Mnd\nszJ9dS7UtDwFDDazrma2lZkdB/QHHkteyczWA04A7kpXiJnda2bXJ/19lZkdZmbbmNkewINAOxpQ\nSyPSXHz6KeywA6T86GtyN90Eu+wSbm5XH4WFhdkJSKQaa64J554bZti9++5Q29KpExx0EEycGJIa\naTq5kLRJLB+8AAAgAElEQVT0Jcy3MgaYTWguGgv8JWW97tG/1XXQ3ZIwF0uFDYE7ozKfAdYBuri7\nWielxXr88dC58MQTQ5+SOLz/Pjz1VBhuWtOU/elMmjQpO0GJ1GKNNcLkdHPmQGEhuIdO5FtsAQMG\nhKRGsi/25qFcouYhae6OOCKM2mnbNsxCe//94cLblM47L9T0zJ0bfsWK5KvS0jDPy4QJ4dYABx4Y\namWOO65lntstpXlIRJrA0qWhL8kf/gD33QennAKnnhr+31S++QbuvRf69m2ZF3VpXtq3D/fNWrAA\nHnwQVq5U7Uu2KWkRaSGmTYMffwy1LautBvfcE6bOP/PM0FbfFMaODU1C55/fNPsTaQprrQU9e8LL\nL4fmo9NPD5+pnXZS35dMU9Ii0kIUFYVJ3HaO5oVu1SrcBfe888JEWnfckd39L10ablzXq1eYjbQh\n0g3DFMklqn3JLiUtIi1EUVGoZUnu/NqqFYwZAxddFJKXUaOyt/8HHoCyMmjMVA6aEVfyhWpfskNJ\ni0gLMH8+zJ6dfk4UMxg5Mtzt9sILw51wM23lylDuMceEKdIbqkdT9xoWyYDqal823zx87lT7UndK\nWkRagKKiUKty6KHpnzeD4cNh0KAwrf4NN2R2/889F0ZaaMp+aclSa1/OOCP0LauofSksVO1LbZS0\niLQARUXQuTNsuGH165jBddfBkCEhefnrXzO3/xEjYO+9Yd99M1emSD5LV/vSs2eofbnsMvj887gj\nzE1KWkSaueXL4fnn6zb7rBkMHQrXXhuSl6uuCpNoNUZJCbz4Yqhlqe9kcqlS75Eiku/S9X254w7Y\nZpswLcEbb8QdYW5R0iLSzL3+OixaVL8p86+8MjQXXXttqHVpTOIyYgRsvXWYcKuxhg8f3vhCRHJU\n+/ah79f8+eFzM3Mm7LUX7L9/mJBxxYq4I4yfkhaRZq6oCDbYIFz86mPAALjlFhg2LNSSNCRxmT8/\nzLx78cWw+ur13z7VxInV3cVDpPlYd93QKf7DD+HRR0PT0XHHhb4vo0bBDz/EHWF8lLSINHNFRaED\nbkOShosuCkOiR46Efv3CxbM+brsN1lknTGKXCW3atMlMQSJ5YLXVoFs3mD4dXnst/PDo3x+23LLl\n9ntR0iLSjC1cCP/+d/3vppzsggvgzjvh738PM9nWNXFZvDhsd9554ZejiDRc585hdNEnn8DZZ8Pt\nt7fMfi9KWkSaseefD0lGY5IWgHPOCRNj3XVXuGDWpW193DgoLw81NCKSGe3awY03hlqWltjvRUmL\nSDNWVBSm7d9yy8aXdeaZ4a7Q994b/r98efXrLl8Ot966agKtTBkwYEDmChPJYy2134uSFpFmyh2m\nTGl8LUuyU04JVdSFhXDaafDzz+nXe+QRmDcv85PJtWvXLrMFiuS5ltbvRUmLSDM1e3aYuCqTSQvA\nSSfBww+HX3c9esBPP1V+3h1uugkOOQQ6dszsvvuprUmkWi2h34uSFpFmqqgoTFy1//6ZL/u440LS\n8tRTcOKJlacenzYNZs0K91QRkaZXU7+Xxx/P734vSlpEmqmionCRat06O+X/8Y/wxBNhP926wY8/\nhuUjRsAuu2S+hkdE6iddv5fzzqu+WTcfKGkRaYaWLg01HtlOHI48Ep5+OkzTn0jAW2+F2pdLLmn8\nlP3plJaWZr5QkWYuud/LO++EGth8paRFpBmaNi3UfDRFbcehh8Kzz8KMGeGGiJtsEtrQs2HgwIHZ\nKVikhdhkk7gjaBwlLSLNUFFRGGq8885Ns78DDwwjlVZfPfRlWXPN7Oxn9OjR2SlYRPJCBu4GIiK5\npqgoNN1ko4mmOvvtB19+md2qZw15FmnZVNMi0szMnx+GO8fREbZ166ZNlESkZVHSItLMFBVBq1ah\nr4mISHOipEWkmSkqCpNMbbhh3JFk3rBhw+IOQURipKRFpBlZvjzcJLG5zpFSXl4edwgiEiMlLSLN\nyOuvw6JFzTdpufrqq+MOQURipKRFpBkpKoINNghTdouINDdKWkSakaKi0AF3dU1mICLNkJIWkWZi\n4UL497/D/CzNVVlZWdwhiEiMlLSINBPPPx9uiNZc+7MA9O7dO+4QRCRGSlpEmokpU8K0/VtsEXck\n2TN06NC4QxCRGClpEWkG3EN/luZcywJQUFAQdwgiEiMlLSLNwOzZsGBB809aRKRlU9Ii0gwUFYUb\nFe6/f9yRiIhkj5IWkWagqCgkLK1bxx1Jdo0fPz7uEEQkRkpaRPLc0qUwbVrLaBoqKSmJOwQRiZGS\nFpE8N20a/Phjy0haxowZE3cIIhIjJS0iea6oKAxz3nnnuCMREckuJS0ieW7KlFDLYhZ3JCIi2RV7\n0mJmrczsGjP7xMzKzewjMxucss5KM1sR/Zv8+HMtZZ9oZnPMbKmZvW1mR2X3aESa1vz5MGdOy2ga\nEhGJPWkBLgfOBS4A2gMDgYFm1jdpnbbAptG/bYHewErgkeoKNbN9gH8AdwG7A08Ak81MlejSbBQV\nQatW4SaJLUEikYg7BBGJUS7cC7YL8IS7T4n+nmdmPYHOFSu4+9fJG5jZscCL7j63hnIvBJ5z95uj\nv/9iZocBfQkJkkjeKyqCzp1hww3jjqRp9O3bt/aVRKTZyoWalhnAIWa2A4CZdQT2BZ5Nt7KZbQx0\nBcbVUm4X4PmUZUXRcpG8t3x5uEliS2oaOvzww+MOQURilAs1LTcA6wGlZraCkEhd6e4Tq1n/TGAx\n8Hgt5bYFvkpZ9lW0XCTvvf46LFrUspIWEWnZciFp6Q70BE4GZhP6n9xqZl+4+/1p1u8FPODuPzVh\njCI5p6gINtgA9tor7khERJpGLjQPDQducPeH3f09d38QGAkMSl3RzH4P7EjtTUMAXwKbpCzbJFpe\no65du5JIJCo9unTpwuTJkyutN3Xq1LQdA/v06VNluvGSkhISiQRlZWWVlg8ZMoRhw4ZVWjZv3jwS\niQSlpaWVlo8aNYoBAwZUWlZeXk4ikWD69OmVlhcWFtKrV68qsXXv3l3H0UyOo6gI9tyzhG7d8vs4\noO7vx+TJk5vFcUDzeD90HC33OAoLC3/5bmzbti2JRIL+/ftX2SbTzN2zvpMaAzArA65w9zuTlg0C\nznD39inrTgB2dvfO1MLMJgKt3f2YpGX/At5297Qdcc2sAJg1a9YsCgoKGnQ8Ik3hu+/gN7+BO++E\ns86KO5qm0717dyZNmhR3GCKSRklJCZ06dQLo5O5ZuedGLjQPPQUMNrPPgfeAAqA/KbUpZrYecEL0\nXBVmdi+wwN2viBbdCrxkZpcAzwA9gE7AOdk4CJGm9PzzsHJly+vPooRFpGXLhaSlL3ANMAbYGPgC\nGBstS9Y9+re6DrpbAisq/nD3mdHQ6euix4fAMe4+O3Ohi8SjqChM27/FFnFHIiLSdGJPWtx9CXBJ\n9KhpvbsIE8VV9/zBaZY9Cjza2BhFcol7SFpOOinuSEREmlYudMQVkXqYPRsWLGh5TUMiIkpaRPJM\nURGstRbsv3/ckTS9dCMaRKTlUNIikmeKikLC0rp13JE0Pc2IK9KyKWkRySNLl8K0aS23aahHjx5x\nhyAiMVLSIpJHpk2DH3+EI4+MOxIRkaanpEUkj0yZEoY5d+gQdyQiIk1PSYtIHikqCk1DZnFHEo/U\n6cZFpGVR0iKSJ+bPhzlzWm5/FoDhw4fHHYKIxEhJi0ieKCqCVq3g0EPjjiQ+EydWNyG2iLQESlpE\n8kRREXTuDBtuGHck8WnTpk3cIYhIjJS0iOSB5cvDTRJbctOQiIiSFpE88PrrsGiRkhYRadmUtIjk\ngaKi0Cy0115xRxKvAQMGxB2CiMRISYtIHpgyJXTAXT32+7LHq127dnGHICIxUtIikuO++y40D6lp\nCPr16xd3CCISIyUtIjnu+edh5UolLSIiSlpEclxREey8c5i+X0SkJat30mJm22YjEBGpyn3V1P0C\npaWlcYcgIjFqSE3LR2b2opmdamZrZTwiEfnF7NmwYIGSlgoDBw6MOwQRiVFDkpYC4B3gZuBLM7vD\nzDpnNiwRgVDLstZasP/+cUeSG0aPHh13CCISo3onLe7+lrtfBGwG9AY2Baab2X/M7BIz+02mgxRp\nqYqKQsLSunXckeQGDXkWadka3BHX3Ze7+2PAicBlwPbATcB8M7vPzDbNUIwiLdLSpTBtGhx5ZNyR\niIjkhgYnLWa2p5n9HfgvcAkhYdkOOIxQC/NERiIUaaFefhl+/FH9WUREKjRk9NAlZvYuMIOQnJwO\nbOXug939U3d/BTiT0PdFRBqoqCgMc+7QIe5IcsewYcPiDkFEYtSQScHPB+4GJrj7f6tZ52vgrAZH\nJSK/DHU2izuS3FFeXh53CCISo3onLe6+Qx3W+Qm4t0ERiQjz58OcOXD11XFHkluu1gsi0qI1pHmo\nl5mdmGb5iWZ2RmbCEmnZioqgVatwk0QREQka0hF3EPBVmuVfA1c0LhwRgZC0dO4MG24YdyQiIrmj\nIUlLO2BemuVzo+dEpBGWLw83SdSooarKysriDkFEYtSQpOVrYLc0yzsC3zYuHBF5/XVYtEjzs6TT\nu3fvuEMQkRg1JGkpBG4zs4PMbLXocTBwKzAxs+GJtBzu8PDDcPzxsNlmsNdecUeUe4YOHRp3CCIS\no4YkLVcBrwEvAEujx1SgGPVpEWmQzz6Do4+Gk06CvfeGV1+F1VaLO6rcU1Cg6Z9EWrKGDHn+Cehu\nZlcRmoSWAu+6+9xMByfS3P38M4wcCUOHwkYbweTJcMwxcUclIpKbGjK5HADu/gHwQQZjEWlRZsyA\n886D996Diy4Kc7Ksu27cUYmI5K4GJS1mtgWQIIwW+r/k59z9kgzEJdJsLVwIl18Od94Z+q288Qbs\nsUfcUeWH8ePHc9ZZmmxbpKWqd9JiZocATwKfAO2B/wBbAwaUZDI4kebEHQoLoX//cAfn0aNDTYv6\nrtRdSUmJkhaRFqwhHXH/Btzk7rsCPwLHA1sCLwMPZzA2kWbjo4/CvCunnAIHHAClpdCnjxKW+hoz\nZkzcIYhIjBqStHQA7ov+vxxo7e4/AH8BLstUYCLNwbJlcO218NvfwocfwjPPwEMPhSHNIiJSPw1J\nWpawqh/Lf4Htkp77daMjEmkmpk2D3XcPHWwvvjh0uO3aNe6oRETyV0M64r4K7AfMAZ4FRpjZrkC3\n6DmRWL3/Ptx1Fzz4IKy/PnTpsuqx887Zb5IpK4OBA+Gee2CffaCkBHbdNbv7FBFpCRqStFwCrBP9\nf0j0/+7Ah9FzIk1u2TJ47LEwIuell+BXv4JTTw338Zk5E+6/H1asCEOK9947JDC/+114/OpXmYnB\nHe67D/7857CvO+6As88Od2uWzEgkEjz55JNxhyEiMalX0mJmqwFbAO8AuPsS4LzGBGBmrYCrgVOA\ntsAXwAR3vzZlvQ7ADcABUdzvAce7++fVlHsGcA/ghJFNAD+6e5vGxCu5paJWZcIE+PZb2H//UMPS\nrRustdaq9ZYsCff0mTkzPMaOhWuuCc/ttFPja2NKS+H880PC1LMn3HwzbLJJpo5SKvTt2zfuEEQk\nRvVKWtx9hZlNJXTGXZShGC4HzgVOB2YDewITzGyRu48GMLPtgFeAuwi3EfgfsAth9FJNvgd2ZFXS\n4hmKWWKUrlblzDPhnHOgffv026y9Nhx4YHhAqBX55JNVSUxDa2N+/BGuvx6GDYN27WDqVDjssMwf\nswSHH3543CGISIwa0jz0H2Bb4NMMxdAFeMLdp0R/zzOznkDnpHWuBZ5x90FJy+qyf3f3bzIUp8Ss\nrrUqdWEG220XHqeeGpZV1Ma8+mpIYm6/vebamJdeCrUrn30WJosbNAhat87gAYuISCUNSVoGAzdF\n9x6aRRhN9At3X1zP8mYA55jZDu7+oZl1BPYF+gOYmQF/AIab2RRgD0LC8jd3f6KWstcxs88Io6RK\ngCvcfXY945MYNaRWpaHqUxuzzjrwww8hcXriCejQIbOxiIhIVQ1JWp6N/n2Sys0tFv1d37EZNwDr\nAaVmtoKQYFzp7hOj5zcmdPa9DLgSGAgcBTxmZge6+yvVlPs+0JvQ/2Z9YAAww8x2dvcv6hmjNLFM\n1qo0VHW1MW+8EWpj2rWDk08O60nTmDx5Mscee2zcYYhITBqStByU4Ri6Az2Bkwl9WnYHbjWzL9z9\nflbNJTPZ3W+L/v+Ome1D6AScNmlx91dJGoJtZjMJw7TPJYx6khzTlLUqDbX22mFG2wMOiDuSlqmw\nsFBJi0gLVu/BmO7+ck2PBsQwHLjB3R929/fc/UFgJFDRf6WMMPPunJTt5hBu2FjXuJcDbwLb17Zu\n165dSSQSlR5dunRh8uTJldabOnUqiUSiyvZ9+vRh/PjxlZaVlJSQSCQoKyurtHzIkCEMGzas0rJ5\n8+aRSCQoLS2ttHzUqFEMGDCg0rLy8nISiQTTp0+vtLywsJBevXpVia179+45dxzvvw8XXVTOuusm\n6NlzOitXhlqVBQtgzz0LGTYsP44Dmsf7kcvHMWnSpGZxHNA83g8dR8s9jsLCwl++G9u2bUsikaB/\n//5Vtsk0c6/fgBoz27+m5919Wj3LKyP0Nbkzadkg4Ax3bx/9/S/gI3c/I2mdx4Bydz+1jvtpRRgm\n/Yy7X1rNOgXArFmzZlFQUFCfw5AGWLgQTjoJnn8+N2tVRESk7kpKSujUqRNAJ3fPyg2UG9I89FKa\nZcmZT337tDwFDDazzwlJRQGhE+64pHVuBCaa2SvAi4Q+LUcT5mwBwMzuBRa4+xXR31cRmoc+AjYg\n9IVpl1KuxOi22+Bf/4IHHoDjj2+6vioiIpKfGpK0bJjy9xqEET3XEDrK1lffaNsxhE63XwBjo2UA\nuPtkMzsPuAK4ldDJtpu7z0wqZ0tgRUqcdxImrFtIGOnUxd0r15lJLMrLYdQo6N073PlYRESkNvVO\nWtz9+zSL/2lmPwE3A53qWd4SwvT/Nd4CwN0nABNqeP7glL9rLVPiM2FCaB66RO+Q1EOvXr245557\n4g5DRGKSybuifAXslMHypJlasQJGjIATToBtt407GsknmhFXpGWrd02Lme2WugjYlDAd/1uZCEqa\nt8ceC5O2TZoUdySSb3r06BF3CCISo4b0aXmLyjchrPAqYTI3kWq5w/DhcPDBsOeecUcjIiL5pCFJ\nyzYpf68EvnH32m5eKMLLL4cZZZ97Lu5IREQk3zRkcrm5KY/5SlikroYPh113hSOOiDsSyUepk2CJ\nSMtS76TFzG4zs75plvc1s1syE5Y0R+++G2pYBgzQ/XqkYYYPHx53CCISo4aMHjoeSPdzZwZwQuPC\nkebspptgyy3DTQZFGmLixIm1ryQizVZDkpaNgP+lWb4Y+HXjwpHm6vPP4R//gIsvhjXWiDsayVdt\n2rSJOwQRiVFDkpaPCNPopzoK+KRx4Uhzdcst4Q7J55wTdyQiIpKvGjJ66GZgtJn9BiiOlh0C/Bm4\nOFOBSfOxaBHceSf06QPrrht3NCIikq8aMnrobkKCchbh5oUvAqcC57v7XZkNT5qDO+6AZcvgwgvj\njkTy3YABA+IOQURi1JCaFtx9LDA2qm1Z6u4/ZDYsaS6WLQtNQ6edBptuGnc0ku/atWsXdwgiEqOG\nTOO/DbC6u3/o7t8kLd8B+NndP8tgfJLnHnwQvvwSLr007kikOejXr1/cIYhIjBrSEXcCsHea5XtT\nw12YpeVZuRJuvBGOOQbat487GhERyXcNSVr2AGamWf4qsHvjwpHm5JlnoLQ0TCYnIiLSWA1JWhxY\nL83y9YHVGheONCfDh8M++8C++8YdiTQXpaWlcYcgIjFqSNIyDRhkZr8kKNH/B5F+plzJMve4I6hq\n5kyYPl21LJJZAwcOjDsEEYlRQ0YPXUZIXN43s1eiZb8n1LQclKnApO4uvBAWLICHH4bVcqSu68Yb\nYccdIZGIOxJpTkaPHh13CCISo4bM0zIb2A14CNgYWBe4D9gxs6FJXaxcGUboPP44/OUvcUcTfPAB\nTJ4cRgy1akhdnkg1NORZpGVr0FeKu3/h7le4+x+A3sCXwBTg7UwGJ7V7+21YuBCOPRauvx6efDLu\niGDECNh44zA3i4iISKY0+Hewme1vZvcCXwCXEmbG/V2mApO6KS6G1q2hsDAMLT79dPj44/ji+eor\nuPfe0GS11lrxxSEiIs1PvZIWM2trZpeb2YfAw4Q7O68JHOvul7v769kIUqr3wgvw+9+HBOHee+E3\nv4Hjj4fy8njiGTUKVl8dzj8/nv1L8zZs2LC4QxCRGNU5aTGzp4D3Cf1ZLgY2c3dNTxmjn3+GadPg\n4IPD3+uvD48+GvqUXHBB048q+uEH+Pvfw52cN9ywafctLUN5XNm4iOSE+tS0HAWMB4a4+zPuviJL\nMUkdvf46LFmyKmkB2G23cIPCe++Fu5r49pXjx8PixdC/f9PuV1qOq6++Ou4QRCRG9Ula9iOMFJpl\nZq+ZWV8z+3WW4pI6KC4OtSt77FF5+WmnheaZfv1CYtMUfv4Zbr4ZevQADfAQEZFsqHPS4u6vuvs5\nwKbAHcDJhE64rYDDzGzd7IQo1XnhBTjggNCHJNXIkbD77nDCCfDtt9mP5eGHYd483RhRRESypyHz\ntCxx97vdfT9gV2AEcDnwtZnlwIDblmHpUpgxAw45JP3za64ZEoklS+CUU2BFFhvz3MOU/UccAR07\nZm8/ImVlZXGHICIxatTUX+7+vrsPBLYAemQmJKmLGTPgp58q92dJ1a5dGAo9dSr89a/Zi+X558N8\nMZqyX7Ktd+/ecYcgIjHKyHyl7r7C3Se7uyZtbyLFxWF48y671LzeYYfBNdeEpOXZZ7MTy/DhUFBQ\ncwIlkglDhw6NOwQRiZEmWc9TxcUhSTCrfd1Bg+Doo+HUU+HTTzMbx5tvhpqWAQPqFotIYxQUFMQd\ngojESElLHlq8OIwKqq4/S6pWreC++8LcKSecAD/+mLlYbrwRtt46lCsiIpJNSlry0LRpoWNtfZpj\nNtwwTDw3e3YYCp0Jn30GDz0El1ySfgSTiIhIJilpyUPFxaGT7bbb1m+73XcPM9aOGwd33934OEaO\nDPPEqG+kNJXx48fHHYKIxEhJSx6qT3+WVL16hWn2L7gASkoaHsO334bkp29fWHvthpcjUh8ljTlp\nRSTvKWnJM2VlYXhxY0bq3HYb/Pa34caK333XsDLGjoWVK0PSItJUxowZE3cIIhIjJS155sUXw7+N\nSVrWWgseeSR06D3ttJB81MfSpeFuzr16hWHXIiIiTUFJS54pLoaddoLNN29cOVtvDQ8+CM89B9df\nX79t77sPvvkmdMAVERFpKkpa8kxFf5ZMOPJIGDIE/vKXMGtuXaxYASNGhKal7bfPTBwiIiJ1oaQl\nj3z+OXzwQWZnnr3qqnDPoJ49Ye7c2td/4gn48ENN2S/xSCQ06bZIS6akJY8UF4d/Dzwwc2W2agUP\nPADrrAMnngjLllW/bsWNEQ84ADp3zlwMInXVVz2/RVo0JS15pLg4zLXy619nttyNNgoTz739Nlx8\ncfXrTZ8Or72mWhaJz+GHHx53CCISo9iTFjNrZWbXmNknZlZuZh+Z2eA063UwsyfMbJGZ/WBmr5nZ\nFrWUfaKZzTGzpWb2tpkdlb0jyS73zPZnSdWpE4weDbffHjrapjN8eLhB41F5+yqKiEg+iz1pAS4H\nzgUuANoDA4GBZvZLPbCZbQe8AswG9gd2Ba4Bqr2LjpntA/wDuAvYHXgCmGxmO2fnMLLr449h/vzs\n3kn57LPDMOZzzw21Lslmz4ann4ZLLw1NSiIiIk0tF75+ugBPuPsUd5/n7o8BU4HkXhPXAs+4+yB3\nf8fdP3X3p929rIZyLwSec/eb3f19d/8LUALkZaN4cTGsthr8/vfZ24cZjBkD7duH0UGLFq167qab\nYLPNQoddkbhMnjw57hBEJEa5kLTMAA4xsx0AzKwjsC/wbPS3AX8APjSzKWb2lZm9ambH1FJuF+D5\nlGVF0fK888ILsNdesN562d1P69ahf8u338IZZ4SJ5774InTW7d8f/u//srt/kZoUFhbGHYKIxCgX\n7s17A7AeUGpmKwiJ1JXuPjF6fmNgHeAy4EpC89FRwGNmdqC7v1JNuW2Br1KWfRUtzysrV4aZcP/0\np6bZ37bbwv33wx//GPqxLFwYkpmm2r9IdSZNmhR3CCISo1xIWroDPYGTCX1WdgduNbMv3P1+VtUG\nTXb326L/vxP1WTmP0NelWXvvvTADbTb7s6Q6+mgYPBiuvDJM+9+3b/ZreURERGqSC81Dw4Eb3P1h\nd3/P3R8ERgKDoufLgOXAnJTt5gDtaij3S2CTlGWbRMtr1LVrVxKJRKVHly5dqrSnT506Ne1kV336\n9GH8+PGVlpWUlJBIJCgrq9wNZ8iQIQwbNqzSsnnz5pFIJCgtLQVCf5Y114S33hrFgJTxxuXl5SQS\nCaZPn15peWFhIb169aoSW/fu3et8HN9+24f27cezfDlceGHjj6PCqFFNexyZfj90HDoOHYeOo6Uf\nR2Fh4S/fjW3btiWRSNC/f/8q22SauXvWd1JjAGZlwBXufmfSskHAGe7ePvr7X8BH7n5G0jqPAeXu\nfmo15U4EWrv7MUnL/gW87e4XVLNNATBr1qxZFBQUZODoMuOYY+B//1s1uVxTKi8PM+V26ND0+xYR\nkfxRUlJCp06dADq5e0k29pELNS1PAYPNrKuZbWVmxwH9gceS1rkR6G5mZ5vZdtFw6KOBX+5Tb2b3\nmlnyrf9uBY40s0vMbCczGwp0AkZn+4AyaflyeOmlpm0aStamjRIWyR3pfv2JSMuRC31a+hLmXBlD\n6HT7BTA2WgaAu082s/OAKwjJyPtAN3efmVTOlsCKpG1mmllP4Lro8SFwjLvPzu7hZFZJCSxeDIcc\nEnckIvHTjLgiLVvsSYu7LwEuiR41rTcBmFDD81XqItz9UeDRxkUYr+LicF+gPfeMOxKR+PXo0SPu\nEBwnP1wAABSgSURBVEQkRrnQPCQ1KC6G/feHNdaIOxIREZF4KWnJYcuWhZsUxtWfRUREJJcoaclh\nr74KS5cqaRGpkDo0U0RaFiUtOay4GH71K+jYMe5IRHLD8OHD4w5BRGKkpCWHFRfDQQfprsoiFSZO\nnFj7SiLSbOnrMEctWRKah9Q0JLJKmzZt4g5BRGKkpCVHvfJKmFhOSYuIiEigpCVHFRfDppvCTjvF\nHYmIiEhuUNKSo4qLwyy4ZnFHIpI7Um/4JiIti5KWHLRwYZi+X01DIpW1a1fTjd1FpLlT0pKDXn4Z\n3JW0iKTq169f3CGISIyUtOSgF16AbbeFrbaKOxIREZHcoaQlBxUXq5ZFREQklZKWHPPllzB7duiE\nKyKVlZaWxh2CiMRISUuOefHF8O9BB8Ubh0guGjhwYNwhiEiMlLTkmOJi2GUX2GSTuCMRyT2jR4+O\nOwQRiZGSlhzzwgvqzyJSHQ15FmnZlLTkkE8/DQ8lLSIiIlUpackhL74Y7uh84IFxRyIiIpJ7lLTk\nkOJiKCiADTaIOxKR3DRs2LC4QxCRGClpyRHump9FpDbl5eVxhyAiMVLSkiNKS+G//1XSIlKTq6++\nOu4QRCRGSlpyRHExrLEG7Ldf3JGIiIjkJiUtOaK4GH73O1h77bgjERERyU1KWnLAypVh5JCahkRq\nVlZWFncIIhIjJS054K23YOFCJS0itendu3fcIYhIjJS05IDiYmjdGvbeO+5IRHLb0KFD4w5BRGKk\npCUHFBeHDrhrrhl3JCK5raCgIO4QRCRGSlpi9vPPMG0aHHJI3JGIiIjkNiUtMXv9dViyRP1ZRERE\naqOkJWYvvADrrw977BF3JCK5b/z48XGHICIxUtISs+JiOOAAWH31uCMRyX0lJSVxhyAiMVLSEqOl\nS2HGDDUNidTVmDFj4g5BRGKkpCVGM2bATz+pE66IiEhdKGmJUXEx/OY3sMsucUciIiKS+5S0xOiF\nF0LTkFnckYiIiOQ+JS0x+f77MNxZ/VlE6i6RSMQdgojESElLTF55JdwoUUmLSN317ds37hBEJEZK\nWmJSXAzt2sF228UdiUj+OPzww+MOQURipKQlJurPIiIiUj+xJy1m1srMrjGzT8ys3Mw+MrPBKevc\nY2YrUx7P1lLuGdF6K5K2Kc/u0dTNN9/AO++oaUhERKQ+Yk9agMuBc4ELgPbAQGCgmaU2Xj8HbAK0\njR496lD290nrtwW2ylDMjfLSS+Hfgw6KNQyRvDN58uS4QxCRGOVC0tIFeMLdp7j7PHd/DJgKdE5Z\nb5m7f+PuX0eP7+tQtqds803Go2+A4mLYcUfYYou4IxHJL4WFhXGHICIxyoWkZQZwiJntAGBmHYF9\ngdTmnwPN7CszKzWzv5vZr+pQ9jpm9pmZzTOzyWa2c4Zjb5DiYs2CK9IQkyZNijsEEYlRLiQtNwCT\ngFIz+wmYBdzi7hOT1nkOOB04mNB8dADwrFmN3VjfB3oDCeAUwrHOMLPNagvouuvgs88acCR18Pnn\n8MEH6s8iIiJSX7mQtHQHegInA3sAZwADzOy0ihXc/SF3f9rd33P3J4GjCc1HB1ZXqLu/6u4PuPs7\n7v4K0A34htB/pkbFxbDDDnDWWfDRR405tPRlAxx4YGbLFRERae5yIWkZDtzg7g9HScmDwEhgUHUb\nuPunQBmwfV134u7LgTfrss3//V9XdtwxwYMPJthhhwRbbJGgY8cuVToBTp06Ne0MnX369GH8+PGV\nlpWUlJBIJHj22TI6doRf/zosHzJkCMOGDau07rx580gkEpSWllZaPmrUKAYMGFBpWXl5OYlEgunT\np1daXlhYSK9evarE1r1794wcR1lZWaXlOg4dh45Dx6HjaDnHUVhYSCKRoEuXLrRt25ZEIkH//v2r\nbJNp5u5Z30mNAZiVAVe4+51JywYBZ7h7+2q22QKYCxzj7k/XcT+tgPeAZ9z90mrWKQBmzZo1i4KC\nApYuhfHjYdgwWLAATjwRBg+GXXet50FG3GGrreCEE+DmmxtWhkhL1qtXL+655564wxCRNEpKSujU\nqRNAJ3cvycY+cqGm5SlgsJl1NbOtzOw4oD/wGICZrW1mw81s7+j5Q4DJwAdAUUUhZnavmV2f9PdV\nZnaYmW1jZnsADwLtgHF1Dax1a+jbNzQRjR0L//437LYbdOsG/9/enQfZUZ1nGH9eIbMIqojZRBIs\nCIuJg8OOMWINIDAuF5DEWCwVnMIQCGGJsyiJbTCLkyBi47AlcQgInMQsic1mthiQic0OAoQlQbEa\nmUUgwAIDZtPJH90TLhfNaGY0o56eeX5VXVL37XPud5tpzUv3OX1nDeI/x2OPwfz5DsKVBssn4kpj\n20gILccA/w2cC8ylul30z8CJ9evvApsDV1INrj0PuBvYpZTydkc/H6F6FkuPDwP/Wvd5DbAasEMp\n5f3XzPphpZXgyCOrAbQXXAAPPgjbbAOf+QzceWf/+7npJlhhBdh554FWIAngoIP683gmSaNV47eH\nRpLu20O9eecduPTSapbRvHkwZQqccMLSw8jUqfDUU3D77UNbtyRJTRsrt4daZ/x4OOSQ6orLZZfB\nc8/BLrtUT7i9+eZq7Eq3xYth5kynOkuSNFiGlmWwwgrV4Nz774fLL4dXXqnGq+y0E1x//fvDy5w5\n1XcOGVqkweue5SBpbDG0DIFx42D//eGee+Caa6qrKvvsA9tvD1ddVYWXm2+uxsZMntx0tVJ7nX76\n6U2XIKlBhpYhlMCnPw233QY/+EE1+2i//WCrrWDGjCqwrLJK01VK7XXJJZcsfSdJo5ahZRgksOee\ncMst1Tc6r7UWPPAAOFtTWjYTJkxougRJDRrfdAGj3a67VsvDD8MGGzRdjSRJ7WVoWU423bTpCiRJ\najdvD0lqje7vTpE0thhaJLXGpEmTmi5BUoMMLZJa49hjj226BEkNMrRIkqRWMLRIkqRWMLRIao2H\nHhrwl7RLGkUMLZJaY9q0aU2XIKlBhhZJrXHOOec0XYKkBhlaJLWGU56lsc3QIkmSWsHQIkmSWsHQ\nIqk1pk+f3nQJkhpkaJHUGq+//nrTJUhqkKFFUmucfPLJTZcgqUGGFkmS1AqGFkmS1AqGFkmtsXDh\nwqZLkNQgQ4uk1jjssMOaLkFSgwwtklrjpJNOaroESQ0ytEhqja233rrpEiQ1yNAiSZJawdAiSZJa\nwdAiqTXOP//8pkuQ1CBDi6TWmDVrVtMlSGqQoUVSa5x77rlNlyCpQYYWSZLUCoYWSZLUCoYWSZLU\nCoYWSa2x7777Nl2CpAYZWiS1xjHHHNN0CZIaZGiR1Bp77bVX0yVIapChRZIktYKhRZIktYKhRVJr\nXHHFFU2XIKlBjYeWJOOSnJrk8SSvJ3k0yVe69pmRZHHXcm0/+j4gybwkbyR5IMk+w/dJJA236dOn\nN12CpAaNb7oA4K+BI4FDgbnAtsCFSX5eSjmnY7/rgD8EUq+/2VenSSYD3wH+CrgGOAS4IslWpZS5\nQ/oJJC0Xa6+9dtMlSGrQSAgtOwBXllKur9efSnIw8Imu/d4spbwwgH6PA64rpZxRr5+YZApwDHD0\nMlUsSZKWu8ZvDwG3AXsk2QQgyRbAjkD37Z/dkixI8lCSf0qyxlL63QG4sWvbDfV2DcDFF1/cdAlL\n1USNw/meQ9X3svYzmPYDbdOGn6+Rrg3H0HN06PsZbNs2n6MjIbScBlwKPJTkLeBe4B9LKZd07HMd\n1e2j3YFpwK7AtUnS3VmHdYEFXdsW1Ns1ACPpB7Y3/oM4PP0YWtqhDcfQc3To+xmLoWUk3B6aChwM\nHEg1pmVL4Mwkz5RS/h2glHJZx/5zkjwIPAbsBswcwlpWBpg3b94Qdtl+ixYtYtasWU2X0acmahzO\n9xyqvpe1n8G0H2ibgex/1113jfifxSZ4ji7/9xwJ5+hg2w7XOdrxu3PlARfVX6WURhfgKeCPu7Z9\nGZi7lHbPA0f08fpPgeO6tp0E3NdHm4OB4uLi4uLi4jLo5eDhygwj4UrLBODdrm2L6ePWVZL1gDWB\nZ/vo93ZgD+Csjm1T6u29uYFqltGTwC/72E+SJL3fysAGVL9Lh0XqKwyNSTKDKlwcBcwBtga+Bfxb\nKeVLSVYFvgp8F3gO2BiYDqwKbF5Kebvu5yLg6VLKl+r1HYAfAn9DNeX5IKrp1Vs75VmSpPYZCaFl\nVeBU4HeBdYBnqJ6vcmop5Z0kKwNXUI11+ZX69RuAEzunQCe5GXiylHJYx7bfB/4WWB94BPjLUsqw\nJUBJkjR8Gg8tkiRJ/TESpjxLkiQtlaFFkiS1gqFlEJKskuTJJKc3XYukSpLVk9ydZFaS2UkOb7om\nSe9Jsl6SmUnmJLk/yWcH3IdjWgYuydeAjYD5pZRpTdcjCeonZK9USvllklWoZiNuU0p5ueHSJAFJ\n1gXWKaXMTjKR6gn4m5RS3uhvH15pGaAkGwObUn21gKQRolR6nq+0Sv1nX1/1IWk5KqU8V0qZXf99\nAbAQWNr3CL6PoWXgvk717Bf/MZRGmPoW0f1UT9r+h1LKS03XJOmDkmwDjCulPD2QdqM6tCTZOclV\nSZ5OsjjJvkvY50+SPJHkjSR3JNmuj/72BR4upTzas2m4apdGu6E+PwFKKYtKKVsCvwEckmTt4apf\nGu2G4xyt26wBXAQcMdCaRnVooXpq7v3A0VTfh/A+SaYC36B64u5WwAPADUnW6tjn6CT3JZlF9e3S\nByZ5nOqKy+FJvjL8H0MalYb0/EyyUs/2+sGTDwA7D+9HkEa1IT9Hk6wIXA78XSnlzoEWNGYG4iZZ\nDOxfSrmqY9sdwJ2llOPr9QDzgbNKKX3ODEryeWAzB+JKy24ozs8k6wCvl1J+kWR14MfAgaWUOcvl\nQ0ij2FD9Dk1yMTCvlHLKYOoY7VdaepXkQ8A2wE0920qV4G4EdmiqLkmDPj/XB36U5D7gFuBMA4s0\nPAZzjibZETgA2L/j6stmA3nfkfAtz01ZC1gBWNC1fQHV7KA+lVIuGo6iJAGDOD9LKXdTXaKWNPwG\nc47eyjLmjjF7pUWSJLXLWA4tC4F3gYld2ycCzy3/ciR18PyURrZGztExG1pKKW9TPY1vj55t9SCi\nPYDbmqpLkuenNNI1dY6O6jEtSVYFNua956lsmGQL4KVSynzgDODCJPcCdwFfBCYAFzZQrjSmeH5K\nI9tIPEdH9ZTnJLsCM/ng/PKLSimH1fscDUyjuqR1P3BsKeWe5VqoNAZ5fkoj20g8R0d1aJEkSaPH\nmB3TIkmS2sXQIkmSWsHQIkmSWsHQIkmSWsHQIkmSWsHQIkmSWsHQIkmSWsHQIkmSWsHQIkmSWsHQ\nIkmSWsHQIkmSWsHQIo1CSWYkWdyxLExyXZLfHkQ/3xuimjrr+XmSHyf5naHouylJZiY5o+k6pLHC\n0CKNXtdRffPqusDuwDvA1Y1WBJ+nqmcysBD4fpINBttZkvFDU1azknyo6RqkNjC0SKPXm6WUF0op\nz5dSZgOnAR9JsmbPDknWS3JpkpeTvJjkiiTr1699lSpk7FdfHXk3yS71a6cleTjJa0keS3JKkhX6\nUdOiup65wFHAKsCUus+9k/yormVhkquTbNhR6/p1HZ9L8sMkrwMHJ1kjyXeS/KyuZ3aSAzvftL4i\nclaSbyZ5KclzSb6QZEKSC5K8kuSRJJ/qavfxJNcmebVu8+0ka9SvzQB2BY7vOD6T+mi3Zlc9Z9f1\nvABc37//pNLYZmiRxoAkqwF/ADxSSnmx3jYeuAFYBOxIdfXjVeD6+rWvA5dR/UKdCPwqcFvd5SvA\nocDHgOOAw4EvDrCsN+s/V6z/XBX4BrA11ZWhd4HLl9Du74Fv1u99A7AycA+wD7AZ8C3g20m27Wp3\nKPACsB1wFvAvwH8BtwJbAf9Tt1sZIMnqwE3AvXVNewPr1G0AjgduB87jveMzv492ly2hnjepjvtR\nfRwnST1KKS4uLqNsAWYAb1OFkFeBxcDPgC079jkEmNvVbkXgNWDPjn6+14/3+3PgrqXssxjYt/77\nBOBc4C3g473sv1bd5rfq9fXr9WP6Uc/VwOkd6zOBWzrWx9XH5cKObRPr/j9Rr38ZuK6r3/XqfTbu\n6PeMrn362+6epn9OXFzatoyK+8GSluhmqv+DD/Bh4GiqqyjblVLmA1sAmyR5tavdSsBGwI29dZxk\nKnBsvd9qwHiqKzZLc3GSxVS3hZ4HDiul/KTuc2PgFGB7qsAyDijAJGBuRx/3dtUyjiooHAD8OlXw\n6glfnWb3/KWUsjjJi8CDHdsWJIHqqghUx2f3JRyfUn/uR3v5jP1tdy+SBsTQIo1er5VSnuhZSXIE\nVbA4AjiRKmzcAxxMFWw6vdBbp0k+CfwHcALVLZVFwEHAn/Wjpj+lunWyqNS3qTp8H3iC6lbTM1Sh\nZQ7v3T76/8/VtT6NKkAdD/ykfv3MJbR7u2u9LGEbvHfbfDXgqrr/7uPz7BLa9ehvu+7PIWkpDC3S\n2FKornIAzAI+B7xQSvlFL/u/BXQPsJ0MPFlKOa1nwwBmAC0opTzevbEe3PpR4AullFvrbTv1Un+3\nycCVpZSL63ap+5rTz5p6Mwv4PeCnpZTFveyzpOPTn3aSBsGBuNLotVKSifXym8DZVGNJeqY9/yfV\ntOMrk+yUZIMkuyU5M8mv1fs8CWye5KNJ1qwH6D4CTEoyNcmGSY4D9l/GWl8GXgT+KMlGSXanGpTb\nHVK6r1xQ1zMlyQ5JPkY1EHfiMtYD1ZibNYBLkmxbf9a969lGPXU8CWxfz2xacwDtJA2CoUUavT5F\ndZvlGeAOYBvgs6WU/wUopbwB7AI8BXyXatzIeVRjWl6p+zgPeJjqNtLzwORSytVUs3fOBu4DPkk1\nFmVplnSVhLqWAkyta3yQKrD8RT/7+BrV1Y3rqcbxPMsHZx0tqV2f20opz1LNqhpHNUtpNnAG8HJd\nL1QzrN6lOnbPJ5nUz3a9HgtJvct755AkSdLI5ZUWSZLUCoYWSZLUCoYWSZLUCoYWSZLUCoYWSZLU\nCoYWSZLUCoYWSZLUCoYWSZLUCoYWSZLUCoYWSZLUCoYWSZLUCoYWSZLUCv8HeixL/ZGTxVcAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a76f150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Beta Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Test accuracy by regularization parameter(logistic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the same approach will improve performance of the 1-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + \\\n",
    "           beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 737.856812\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 28.0%\n",
      "Minibatch loss at step 500: 193.145432\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 113.938164\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 68.555458\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 2000: 41.568699\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 2500: 25.307682\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 3000: 15.500218\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.8%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this comutation and iterate\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul: 1e-3}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time got accuracy over 90% whew!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4,-2,0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for regul in regul_val:\n",
    "    with tf.Session(graph = graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for step in range(num_steps):\n",
    "            #Pick an offset within the training data, which is randomized\n",
    "            #Note: we could use better randomization across epochs\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            #Prepare a dictionary telling the session where to feed the minibatch\n",
    "            # and value is the numpy array to feed to it\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : regul}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGNCAYAAACxGxMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x144f49390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Beta Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Test accuracy by regularization parameter(logistic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 367.239532\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 21.9%\n",
      "Test accuracy: 67.5%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this comutation and iterate\n",
    "num_steps = 101\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    #offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    offset = step % num_batches\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul: 1e-3}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGNCAYAAACxGxMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ea8f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Beta Parameter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Test accuracy by regularization parameter(logistic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is far too much parameter and no regularization, the accuracy of the batches (training) reached very hight but \n",
    "it didn't generalize too well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "    logits = tf.matmul(drop1, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 461.604187\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 16.4%\n",
      "Test accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this comutation and iterate\n",
    "num_steps = 101\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_batches\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul: 1e-3}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy has increased because of use of dropout which reduced coadoption properties of activation unit/neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do that first two layers and change how the parameters are initialized, compared to previous cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 100\n",
    "beta_regul = 1e-3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden_nodes1], \n",
    "                            stddev=np.sqrt(2.0 / (image_size * image_size)))\n",
    "    )\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    weights3 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes2, num_labels], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "    biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    lay2_train = tf.nn.relu(tf.matmul(lay1_train, weights2) + biases2)        \n",
    "    #drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "    logits = tf.matmul(lay2_train, weights3) + biases3\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + \\\n",
    "        beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3))\n",
    "    # Optimizer\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.65, staircase = True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)        \n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay2_test, weights3) + biases3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.143208\n",
      "Minibatch accuracy: 21.1%\n",
      "Validation accuracy: 32.3%\n",
      "Minibatch loss at step 500: 1.023426\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1000: 1.044920\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 1500: 0.623559\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 2000: 0.640721\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 2500: 0.517430\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 3000: 0.551429\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 3500: 0.527504\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 4000: 0.423207\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 4500: 0.559187\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 5000: 0.611271\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 5500: 0.500356\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 6000: 0.373803\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 6500: 0.475060\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 7000: 0.423939\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 7500: 0.470834\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 8000: 0.418889\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 8500: 0.375226\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 9000: 0.378199\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Test accuracy: 95.5%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this comutation and iterate\n",
    "num_steps = 9001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_batches\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going great, now try one more layer deeper in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 256\n",
    "num_hidden_nodes3 = 128\n",
    "keep_prob = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden_nodes1], \n",
    "                            stddev=np.sqrt(2.0 / (image_size * image_size)))\n",
    "    )\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    weights3 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "    biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    weights4 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes3, num_labels], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes3)))\n",
    "    biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    lay2_train = tf.nn.relu(tf.matmul(lay1_train, weights2) + biases2)   \n",
    "    lay3_train = tf.nn.relu(tf.matmul(lay2_train, weights3) + biases3)        \n",
    "    \n",
    "    #drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "    logits = tf.matmul(lay3_train, weights4) + biases4\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + \\\n",
    "        beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3) + tf.nn.l2_loss(weights4))\n",
    "    # Optimizer\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 4000, 0.65, staircase = True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)     \n",
    "    lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights4) + biases4)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights3) + biases3)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights4) + biases4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.497494\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 20.7%\n",
      "Minibatch loss at step 500: 1.147982\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 1000: 1.089037\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1500: 0.655303\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 2000: 0.662725\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 2500: 0.526266\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3000: 0.513025\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 3500: 0.539301\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4000: 0.414465\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4500: 0.538997\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 5000: 0.630841\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5500: 0.531141\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6000: 0.364852\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 6500: 0.545709\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7000: 0.430829\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 7500: 0.490148\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8000: 0.419793\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8500: 0.369246\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 9000: 0.367205\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 9500: 0.519761\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 10000: 0.494777\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10500: 0.420177\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 11000: 0.333671\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11500: 0.365290\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 12000: 0.390995\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 12500: 0.351320\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13000: 0.338039\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13500: 0.415195\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 14000: 0.350410\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 14500: 0.453269\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 15000: 0.430039\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 15500: 0.462806\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 16000: 0.354612\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 16500: 0.307644\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 17000: 0.306982\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 17500: 0.253938\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 18000: 0.308958\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.5%\n",
      "Test accuracy: 95.7%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this computation and iterate\n",
    "num_steps = 18001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_batches\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we can increase the width by increasing the number of activation unit in each layer but that won't help\n",
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 512\n",
    "num_hidden_nodes2 = 256\n",
    "keep_prob = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #Input data. For the training data, we use a placeholder that will be fed\n",
    "    #at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #Variables\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden_nodes1], \n",
    "                            stddev=np.sqrt(2.0 / (image_size * image_size)))\n",
    "    )\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    weights3 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "    biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    weights4 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes3, num_labels], \n",
    "                            stddev= np.sqrt(2.0 / num_hidden_nodes3)))\n",
    "    biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "    #Training computation\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    lay2_train = tf.nn.relu(tf.matmul(lay1_train, weights2) + biases2)   \n",
    "    lay3_train = tf.nn.relu(tf.matmul(lay2_train, weights3) + biases3)        \n",
    "    \n",
    "    #drop1 = tf.nn.dropout(lay1_train, 0.5)\n",
    "    logits = tf.matmul(lay3_train, weights4) + biases4\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + \\\n",
    "        beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3) + tf.nn.l2_loss(weights4))\n",
    "    # Optimizer\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 5000, 0.80, staircase = True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    #Prediction for the training, validation and test sets\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)     \n",
    "    lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights4) + biases4)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights3) + biases3)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights4) + biases4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.508031\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 17.9%\n",
      "Minibatch loss at step 500: 1.158002\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 1000: 1.098492\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 1500: 0.661303\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 2000: 0.691450\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 2500: 0.505425\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3000: 0.541973\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 3500: 0.539747\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 4000: 0.436021\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 4500: 0.564675\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5000: 0.663260\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5500: 0.550075\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6000: 0.361015\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 6500: 0.585573\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 7000: 0.427508\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 7500: 0.497115\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 8000: 0.465639\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 8500: 0.423356\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 9000: 0.388208\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 9500: 0.580035\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 10000: 0.516785\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 10500: 0.447384\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11000: 0.345584\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 11500: 0.393954\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 12000: 0.423413\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 12500: 0.399813\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 13000: 0.417805\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 13500: 0.482252\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 14000: 0.392991\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 14500: 0.529329\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 15000: 0.461151\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 15500: 0.515227\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 16000: 0.394144\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 16500: 0.369302\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 17000: 0.378902\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 17500: 0.322934\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 18000: 0.384397\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 18500: 0.311028\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 19000: 0.434950\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 19500: 0.297700\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 20000: 0.441114\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.0%\n",
      "Test accuracy: 95.4%\n"
     ]
    }
   ],
   "source": [
    "#Lets run this computation and iterate\n",
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #pick the offset in the training data which has been radomized.\n",
    "    # Note: we could use better randomization across epochs\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_batches\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "    #Prepare a dictionalry telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the is the placeholder node for the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
