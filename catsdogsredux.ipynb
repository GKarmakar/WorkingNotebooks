{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinakarmakar/anaconda2\n",
      "/Users/trinakarmakar/anaconda2/data/fastai/redux/\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print current_dir\n",
    "data_dir = current_dir + '/data/fastai/redux/'\n",
    "print data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd $data_dir\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd $data_dir/train\n",
    "\n",
    "g = glob('*.jpg')\n",
    "shuff = np.random.permutation(g)\n",
    "for i in range(2000): \n",
    "    os.rename(shuff[i], data_dir+'valid/'+shuff[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuff = np.random.permutation(g)\n",
    "for i in range(200): \n",
    "    os.rename(shuff[i], data_dir+'sample/train/'+shuff[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuff = np.random.permutation(g)\n",
    "for i in range(50): \n",
    "    os.rename(shuff[i], data_dir+'sample/valid/'+shuff[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd $data_dir/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg ./cats/\n",
    "%mv dog.*.jpg ./dogs/\n",
    "\n",
    "%cd $data_dir/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg ./cats/\n",
    "%mv dog.*.jpg ./dogs/\n",
    "\n",
    "%cd $data_dir/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg ./cats/\n",
    "%mv dog.*.jpg ./dogs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinakarmakar/anaconda2/data/fastai/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $data_dir/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg ./cats/\n",
    "%mv dog.*.jpg ./dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinakarmakar/anaconda2/data/fastai/redux/test\n",
      "/Users/trinakarmakar/anaconda2/data/fastai/redux/test\n"
     ]
    }
   ],
   "source": [
    "%cd $data_dir/test\n",
    "print os.getcwd()\n",
    "%mkdir unknown\n",
    "%mv *.jpg ./unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = data_dir+'train/'\n",
    "test_path = data_dir + 'test/'\n",
    "result_path = data_dir + 'results/'\n",
    "valid_path = data_dir + 'valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinakarmakar/anaconda2/data/fastai/redux/valid/\n"
     ]
    }
   ],
   "source": [
    "print valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "nb_epoch = 1\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1cc1b6c57022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#we will be fitting our data against train and validate against valid set and store our weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatest_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"running epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#we will be fitting our data against train and validate against valid set and store our weights\n",
    "latest_weight_file = None\n",
    "for epoch in range(nb_epoch):\n",
    "    print \"running epoch %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weight_file = \"ft%d.h5\" % epoch\n",
    "    vgg.model.save_weights(result_path, latest_weight_file)\n",
    "print(\"Completed %s fit operations\" % nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate prediction\n",
    "batches, preds = vgg.test(test_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each image vgg.test generates two probabilities baed on how we ordered cats and dogs,\n",
    "preds[:5]\n",
    "filenames = batches.filenames\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can verify column ordering by visualizing some images\n",
    "from PIL import Image\n",
    "Image(test_path+filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save your test results in arrayas so that we can use it later\n",
    "save_array(results_path+'test_pred.dat', preds)\n",
    "save_array(results_path+'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validate predictions\n",
    "vgg.load_models(results_path+latest_weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches, val_proba = vgg.test(vali_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batch.filenames\n",
    "expected_labels = val_batches.classes #0 or 1\n",
    "#round our predictions to 0 or 1\n",
    "our_predictions = val_proba[:,0]\n",
    "our_labels = np.round(1-ourp_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plots is the helper function in the utils to let us plot images in our validation set\n",
    "from keras.processing import image\n",
    "def plots_index(idx, title=None):\n",
    "    plots(image.loadimg(valid_path+filenames[i] for i in idx, titles = titles)\n",
    "          \n",
    "#Number of images to view\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 A few correct labales\n",
    "correct_labels = np.where(our_labels == expected_lables)[0]\n",
    "print \"Found %d correct labels\" % len(correct_labels)\n",
    "idx = np.permutation(correct_labels)[:n_view]\n",
    "plots_index(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2 Few incorrect labels\n",
    "incorrect_labels = np.where(our_labels != expected_lables)\n",
    "print \"found %d incorrect labels\" % len(incorrect_labels)\n",
    "idx = np.permutations(incorrect_labels)[:n_view]\n",
    "plots_index(idx, ur_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3a Images we are most confident as cats are actully cats\n",
    "correct_cats = np.where((our_labels == 0) & (our_labels == expected_labels))[0]\n",
    "print \"Found %d confident cats lables\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_vew]\n",
    "plots_index(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b Images we are most confident as dogs are actually dogs\n",
    "correct_dogs = n.where((our_labels == 1) & (our_labels == expected_labels))[0]\n",
    "print \"Found %d of correct dogs\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_index(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3c Images we are most confident as cats are actully dogs\n",
    "incorrect_cats = np.where((our_labels == 0) & (our_labels != expected_labels))[0]\n",
    "print \"Found %d incorrect cats lables\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_vew]\n",
    "    plots_index(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3d Images we are most confident as cats are actully dogs\n",
    "incorrect_dogs = np.where((our_labels == 1) & (our_labels != expected_labels))[0]\n",
    "print \"Found %d incorrect dogs lables\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[::-1][:n_vew]\n",
    "    plots_index(incorrect_cats[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Most incorrect predictions (i.e. whose proba is closest to 0.5)\n",
    "most_uncertain = np.argsort(np.abs(our_predictions - 0.5))\n",
    "plots_index(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Most common way to analyze classification error is confusion matrix\n",
    "from sklearn.matrix import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare for the kaggle submission\n",
    "#Load our saved array\n",
    "preds = load_array(results_path+'test_preds.dat')\n",
    "filenames = load_array(results_path+'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab the dog predictions file\n",
    "isdog = preds[:,1]\n",
    "print \"Raw Predictions:\" + str(isdog[:5])\n",
    "print \"Mid Predictions:\" + str(isdog[(isdog < 0.6) & (isdog > 0.4)])\n",
    "print \"Edge Predictions:\" + str(isdog[(isdog  == 1) & (isdog == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize log loss\n",
    "from sklearn.metrics import log_loss\n",
    "x = [i * .0001 for i in range(1,10000)]\n",
    "y = [log_loss([1], [[i*.0001,1-(i*.0001)]],eps=1e-15) for i in range(1,10000,1)])]\n",
    "plt.plot(x,y)\n",
    "plt.axis([-.05, 1.1, -.8, 10])\n",
    "plt.title(\"Log Loss when true label = 1\")\n",
    "plt.xlabel(\"predicted probability\")\n",
    "plt.ylabel(\"log loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Play a trick swap all 0s with 0.05 and all ones with 0.95 for our edge predctions\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract image IDs from our filenames into test/unknown directory\n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we we join two variable into an array [ImageID, isdog]\n",
    "subm = np.stack([ids, isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $data_dir\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt = '%d,%0.5f', header='id,label', comments='')\n",
    "from IPython.display import FileLink\n",
    "%cd $data_dir\n",
    "FileLink(submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
